{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.5\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from config import OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       " 'punchline': 'Because it was two tired!'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your desired data structure.\n",
    "# class Joke(BaseModel):\n",
    "#     setup: str = Field(description=\"question to set up a joke\")\n",
    "#     punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n return a JSON dictionary with a key setup that contains the question to set up a joke and a punchline that answer to resolve the joke\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sections': [{'section': 'Information that I saw online about COVID-19 disease causing sterility in the summer was removed.',\n",
       "   'category': 'bias',\n",
       "   'sub_category': 'misinformation',\n",
       "   'explanation': 'The statement suggests biased or misleading information about COVID-19 causing sterility.'},\n",
       "  {'section': 'I heard it’s because of lawsuits related to Bill Gates and the vaccines in Africa.',\n",
       "   'category': 'bias',\n",
       "   'sub_category': 'conspiracy theory',\n",
       "   'explanation': 'The mention of Bill Gates and vaccines in Africa hints at a biased conspiracy theory.'},\n",
       "  {'section': 'Does this have to do with the COVID-19 vaccines causing infertility?',\n",
       "   'category': 'bias',\n",
       "   'sub_category': 'misinformation',\n",
       "   'explanation': 'The question implies biased information about COVID-19 vaccines causing infertility without factual basis.'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Section(BaseModel):\n",
    "    section: str = Field(description=\"text section relevant for identification as sub_category\")\n",
    "    category: str = Field(description=\"category that best describes the section\")\n",
    "    sub_category: str = Field(description=\"specifies a subtype or aspect within the category\")\n",
    "    explanation: str = Field(description=\"brief explanation why this section is identified\")\n",
    "    \n",
    "analysis_template = \"\"\"\n",
    "    Identify all text sections relevant to these categories: {categories}.\n",
    "    Create a JSON object containing a list of identified 'sections' with the key 'sections'.\n",
    "    Each 'section' is in the format: {format_instructions}\n",
    "    If none of the given categories are clearly identifiable in the text, return an empty object.\n",
    "    Text: {text}\n",
    "\"\"\"\n",
    "\n",
    "categories = \"bias, logical fallacy\"\n",
    "text = \"\"\"\n",
    "Information that I saw online about COVID-19 disease causing sterility in the summer was removed.\n",
    "I heard it’s because of lawsuits related to Bill Gates and the vaccines in Africa.\n",
    "Does this have to do with the COVID-19 vaccines causing infertility?\n",
    "\"\"\"\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Section)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = analysis_template,\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    input_variables=['categories', 'text'],\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"categories\": categories, \"text\": text})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
